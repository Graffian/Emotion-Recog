{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b1f6ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2 as cv\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c386ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import Ima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "92b222a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 22968 files for training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  color_mode=\"grayscale\",\n",
    "  labels=\"inferred\",\n",
    "  label_mode = \"categorical\",\n",
    ")\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ce301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2a6d80de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 5741 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  labels=\"inferred\",\n",
    "  color_mode=\"grayscale\",\n",
    "  label_mode = \"categorical\",\n",
    "\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb06fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0fb09879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\HP\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:593: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2311 - loss: 1.8427 - val_accuracy: 0.2686 - val_loss: 1.7788\n",
      "Epoch 2/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2986 - loss: 1.7374 - val_accuracy: 0.2904 - val_loss: 1.7889\n",
      "Epoch 3/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3189 - loss: 1.7003 - val_accuracy: 0.3395 - val_loss: 1.6809\n",
      "Epoch 4/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3387 - loss: 1.6777 - val_accuracy: 0.3259 - val_loss: 1.6948\n",
      "Epoch 5/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3513 - loss: 1.6569 - val_accuracy: 0.3435 - val_loss: 1.6668\n",
      "Epoch 6/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3562 - loss: 1.6411 - val_accuracy: 0.3496 - val_loss: 1.6593\n",
      "Epoch 7/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3570 - loss: 1.6335 - val_accuracy: 0.3550 - val_loss: 1.6535\n",
      "Epoch 8/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.3657 - loss: 1.6262 - val_accuracy: 0.3574 - val_loss: 1.6350\n",
      "Epoch 9/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.3766 - loss: 1.6069 - val_accuracy: 0.3658 - val_loss: 1.6424\n",
      "Epoch 10/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 21ms/step - accuracy: 0.3682 - loss: 1.6069 - val_accuracy: 0.3517 - val_loss: 1.6651\n",
      "Epoch 11/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.3771 - loss: 1.5940 - val_accuracy: 0.3649 - val_loss: 1.6238\n",
      "Epoch 12/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.3821 - loss: 1.5876 - val_accuracy: 0.3707 - val_loss: 1.6062\n",
      "Epoch 13/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.3862 - loss: 1.5774 - val_accuracy: 0.3707 - val_loss: 1.6104\n",
      "Epoch 14/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.3934 - loss: 1.5629 - val_accuracy: 0.3785 - val_loss: 1.6139\n",
      "Epoch 15/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.3946 - loss: 1.5635 - val_accuracy: 0.3700 - val_loss: 1.6142\n",
      "Epoch 16/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.3975 - loss: 1.5564 - val_accuracy: 0.3792 - val_loss: 1.6080\n",
      "Epoch 17/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.4017 - loss: 1.5406 - val_accuracy: 0.3668 - val_loss: 1.6044\n",
      "Epoch 18/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.4037 - loss: 1.5334 - val_accuracy: 0.3714 - val_loss: 1.6254\n",
      "Epoch 19/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4039 - loss: 1.5271 - val_accuracy: 0.3733 - val_loss: 1.6179\n",
      "Epoch 20/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4115 - loss: 1.5202 - val_accuracy: 0.3877 - val_loss: 1.5894\n",
      "Epoch 21/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4164 - loss: 1.5061 - val_accuracy: 0.3811 - val_loss: 1.6177\n",
      "Epoch 22/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4204 - loss: 1.5023 - val_accuracy: 0.3714 - val_loss: 1.6081\n",
      "Epoch 23/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.4251 - loss: 1.4916 - val_accuracy: 0.3668 - val_loss: 1.6423\n",
      "Epoch 24/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4235 - loss: 1.4888 - val_accuracy: 0.3815 - val_loss: 1.6424\n",
      "Epoch 25/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.4254 - loss: 1.4776 - val_accuracy: 0.3766 - val_loss: 1.6153\n",
      "Epoch 26/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.4274 - loss: 1.4720 - val_accuracy: 0.3888 - val_loss: 1.6001\n",
      "Epoch 27/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.4348 - loss: 1.4624 - val_accuracy: 0.3897 - val_loss: 1.6232\n",
      "Epoch 28/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4351 - loss: 1.4647 - val_accuracy: 0.3656 - val_loss: 1.6490\n",
      "Epoch 29/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4427 - loss: 1.4512 - val_accuracy: 0.3796 - val_loss: 1.6385\n",
      "Epoch 30/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.4490 - loss: 1.4394 - val_accuracy: 0.3844 - val_loss: 1.6259\n",
      "Epoch 31/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.4495 - loss: 1.4355 - val_accuracy: 0.3863 - val_loss: 1.6415\n",
      "Epoch 32/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4524 - loss: 1.4293 - val_accuracy: 0.3897 - val_loss: 1.6397\n",
      "Epoch 33/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.4540 - loss: 1.4187 - val_accuracy: 0.3802 - val_loss: 1.6276\n",
      "Epoch 34/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4570 - loss: 1.4134 - val_accuracy: 0.3917 - val_loss: 1.6242\n",
      "Epoch 35/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.4641 - loss: 1.3984 - val_accuracy: 0.3881 - val_loss: 1.6325\n",
      "Epoch 36/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.4663 - loss: 1.3979 - val_accuracy: 0.3789 - val_loss: 1.6502\n",
      "Epoch 37/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.4652 - loss: 1.3975 - val_accuracy: 0.3904 - val_loss: 1.6464\n",
      "Epoch 38/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.4725 - loss: 1.3822 - val_accuracy: 0.3863 - val_loss: 1.6383\n",
      "Epoch 39/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.4715 - loss: 1.3794 - val_accuracy: 0.3905 - val_loss: 1.6707\n",
      "Epoch 40/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.4819 - loss: 1.3686 - val_accuracy: 0.3796 - val_loss: 1.7139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19267f831c0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Rescaling\n",
    "model = Sequential([\n",
    "    Rescaling(1./255,\n",
    "              input_shape=(48,48,1)),  # Tell the model what shape to expect\n",
    "    layers.Flatten(),                 # Convert 48x48x1 to 2304x1 (48*48=2304)\n",
    "    layers.Dense(256,activation=\"relu\"),\n",
    "    layers.Dense(128,activation=\"relu\"),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(32,activation=\"relu\"),\n",
    "    layers.Dense(16,activation=\"relu\"),\n",
    "    layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "model.fit(train_ds,validation_data=val_ds,epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5278d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_training_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  labels=\"inferred\",\n",
    "  color_mode=\"grayscale\",\n",
    "  label_mode = \"categorical\",\n",
    "\n",
    ")\n",
    "test_training_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c0ca4daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.4426 - loss: 1.4535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.493155598640442, 0.4326517879962921]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_training_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7f5b5450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion_model.pkl']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model , \"emotion_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe5940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf0857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b78e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
