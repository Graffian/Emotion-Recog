{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f6ffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\tfenv\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2 as cv\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c386ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b222a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 22968 files for training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  color_mode=\"grayscale\",\n",
    "  labels=\"inferred\",\n",
    "  label_mode = \"categorical\",\n",
    ")\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ce301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6d80de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 5741 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  labels=\"inferred\",\n",
    "  color_mode=\"grayscale\",\n",
    "  label_mode = \"categorical\",\n",
    "\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb06fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fb09879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.2801 - loss: 1.7669 - val_accuracy: 0.3764 - val_loss: 1.5988\n",
      "Epoch 2/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.3897 - loss: 1.5638 - val_accuracy: 0.4076 - val_loss: 1.5291\n",
      "Epoch 3/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 38ms/step - accuracy: 0.4354 - loss: 1.4605 - val_accuracy: 0.4365 - val_loss: 1.4805\n",
      "Epoch 4/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 34ms/step - accuracy: 0.4755 - loss: 1.3671 - val_accuracy: 0.4355 - val_loss: 1.4721\n",
      "Epoch 5/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 32ms/step - accuracy: 0.5147 - loss: 1.2874 - val_accuracy: 0.4329 - val_loss: 1.4699\n",
      "Epoch 6/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.5466 - loss: 1.2142 - val_accuracy: 0.4410 - val_loss: 1.4685\n",
      "Epoch 7/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.5788 - loss: 1.1422 - val_accuracy: 0.4262 - val_loss: 1.5086\n",
      "Epoch 8/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 35ms/step - accuracy: 0.6058 - loss: 1.0603 - val_accuracy: 0.4449 - val_loss: 1.5531\n",
      "Epoch 9/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 34ms/step - accuracy: 0.6375 - loss: 0.9817 - val_accuracy: 0.4546 - val_loss: 1.5747\n",
      "Epoch 10/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.6731 - loss: 0.8939 - val_accuracy: 0.4431 - val_loss: 1.6599\n",
      "Epoch 11/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.7078 - loss: 0.8187 - val_accuracy: 0.4227 - val_loss: 1.7944\n",
      "Epoch 12/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.7329 - loss: 0.7416 - val_accuracy: 0.4370 - val_loss: 1.8350\n",
      "Epoch 13/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.7663 - loss: 0.6586 - val_accuracy: 0.4208 - val_loss: 1.9862\n",
      "Epoch 14/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.7916 - loss: 0.5948 - val_accuracy: 0.4410 - val_loss: 2.1557\n",
      "Epoch 15/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.8189 - loss: 0.5263 - val_accuracy: 0.4424 - val_loss: 2.3060\n",
      "Epoch 16/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.8406 - loss: 0.4689 - val_accuracy: 0.4236 - val_loss: 2.5649\n",
      "Epoch 17/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.8613 - loss: 0.4125 - val_accuracy: 0.4332 - val_loss: 2.6799\n",
      "Epoch 18/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.8692 - loss: 0.3841 - val_accuracy: 0.4262 - val_loss: 2.8386\n",
      "Epoch 19/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.8902 - loss: 0.3361 - val_accuracy: 0.4255 - val_loss: 3.0523\n",
      "Epoch 20/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.9010 - loss: 0.3023 - val_accuracy: 0.4194 - val_loss: 3.2678\n",
      "Epoch 21/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - accuracy: 0.9105 - loss: 0.2708 - val_accuracy: 0.4167 - val_loss: 3.4061\n",
      "Epoch 22/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.9218 - loss: 0.2427 - val_accuracy: 0.4292 - val_loss: 3.4959\n",
      "Epoch 23/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.9206 - loss: 0.2422 - val_accuracy: 0.4266 - val_loss: 3.5845\n",
      "Epoch 24/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.9274 - loss: 0.2161 - val_accuracy: 0.4173 - val_loss: 3.9107\n",
      "Epoch 25/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.9308 - loss: 0.2129 - val_accuracy: 0.4334 - val_loss: 3.9581\n",
      "Epoch 26/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.9257 - loss: 0.2264 - val_accuracy: 0.4243 - val_loss: 4.0836\n",
      "Epoch 27/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9360 - loss: 0.1864 - val_accuracy: 0.4198 - val_loss: 3.9519\n",
      "Epoch 28/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9418 - loss: 0.1815 - val_accuracy: 0.4193 - val_loss: 4.3439\n",
      "Epoch 29/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9490 - loss: 0.1610 - val_accuracy: 0.4146 - val_loss: 4.7567\n",
      "Epoch 30/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9487 - loss: 0.1585 - val_accuracy: 0.4254 - val_loss: 4.5906\n",
      "Epoch 31/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9549 - loss: 0.1383 - val_accuracy: 0.4212 - val_loss: 4.6369\n",
      "Epoch 32/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9567 - loss: 0.1374 - val_accuracy: 0.4158 - val_loss: 4.9371\n",
      "Epoch 33/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9498 - loss: 0.1544 - val_accuracy: 0.4229 - val_loss: 5.0681\n",
      "Epoch 34/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.9581 - loss: 0.1287 - val_accuracy: 0.4250 - val_loss: 4.9600\n",
      "Epoch 35/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9514 - loss: 0.1438 - val_accuracy: 0.4254 - val_loss: 4.9487\n",
      "Epoch 36/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9614 - loss: 0.1224 - val_accuracy: 0.4247 - val_loss: 5.0564\n",
      "Epoch 37/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9654 - loss: 0.1082 - val_accuracy: 0.4278 - val_loss: 5.2187\n",
      "Epoch 38/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9614 - loss: 0.1206 - val_accuracy: 0.4250 - val_loss: 5.1985\n",
      "Epoch 39/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.9648 - loss: 0.1114 - val_accuracy: 0.4219 - val_loss: 5.4260\n",
      "Epoch 40/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9671 - loss: 0.1035 - val_accuracy: 0.4221 - val_loss: 5.3093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f0456d4070>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Rescaling\n",
    "model = Sequential([\n",
    "    Rescaling(1./255),\n",
    "    layers.Conv2D(filters=32 , kernel_size=(3,3) , strides=(1,1) , activation=\"relu\" , input_shape=(48,48,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(32,activation=\"relu\"),\n",
    "    layers.Dense(16,activation=\"relu\"),\n",
    "    layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "model.fit(train_ds,validation_data=val_ds,epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5278d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_training_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  labels=\"inferred\",\n",
    "  color_mode=\"grayscale\",\n",
    "  label_mode = \"categorical\",\n",
    "\n",
    ")\n",
    "test_training_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ca4daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8686 - loss: 0.5363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3978391885757446, 0.7902747988700867]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_training_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f5b5450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion_model.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model , \"emotion_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe5940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf0857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b78e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
