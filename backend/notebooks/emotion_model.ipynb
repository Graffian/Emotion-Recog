{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f6ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2 as cv\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c386ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b222a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 22968 files for training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  color_mode=\"grayscale\",\n",
    "  labels=\"inferred\",\n",
    "  label_mode = \"categorical\",\n",
    ")\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ce301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6d80de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 5741 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  labels=\"inferred\",\n",
    "  color_mode=\"grayscale\",\n",
    "  label_mode = \"categorical\",\n",
    "\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb06fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb09879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\HP\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:593: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.2430 - loss: 1.8729 - val_accuracy: 0.2547 - val_loss: 1.7962\n",
      "Epoch 2/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2656 - loss: 1.7897 - val_accuracy: 0.2536 - val_loss: 1.8262\n",
      "Epoch 3/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2974 - loss: 1.7430 - val_accuracy: 0.3205 - val_loss: 1.7189\n",
      "Epoch 4/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3223 - loss: 1.7120 - val_accuracy: 0.3125 - val_loss: 1.7181\n",
      "Epoch 5/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3312 - loss: 1.6928 - val_accuracy: 0.3442 - val_loss: 1.6860\n",
      "Epoch 6/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3434 - loss: 1.6664 - val_accuracy: 0.3271 - val_loss: 1.6985\n",
      "Epoch 7/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3492 - loss: 1.6518 - val_accuracy: 0.3440 - val_loss: 1.6730\n",
      "Epoch 8/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3590 - loss: 1.6380 - val_accuracy: 0.3517 - val_loss: 1.6550\n",
      "Epoch 9/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3602 - loss: 1.6259 - val_accuracy: 0.3480 - val_loss: 1.6514\n",
      "Epoch 10/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3663 - loss: 1.6182 - val_accuracy: 0.3468 - val_loss: 1.6627\n",
      "Epoch 11/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3731 - loss: 1.6061 - val_accuracy: 0.3675 - val_loss: 1.6243\n",
      "Epoch 12/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3751 - loss: 1.5979 - val_accuracy: 0.3689 - val_loss: 1.6191\n",
      "Epoch 13/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.3777 - loss: 1.5924 - val_accuracy: 0.3484 - val_loss: 1.6476\n",
      "Epoch 14/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3812 - loss: 1.5818 - val_accuracy: 0.3616 - val_loss: 1.6180\n",
      "Epoch 15/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3772 - loss: 1.5803 - val_accuracy: 0.3620 - val_loss: 1.6302\n",
      "Epoch 16/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3835 - loss: 1.5751 - val_accuracy: 0.3705 - val_loss: 1.6046\n",
      "Epoch 17/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3904 - loss: 1.5567 - val_accuracy: 0.3628 - val_loss: 1.6309\n",
      "Epoch 18/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3937 - loss: 1.5530 - val_accuracy: 0.3693 - val_loss: 1.6137\n",
      "Epoch 19/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3967 - loss: 1.5479 - val_accuracy: 0.3688 - val_loss: 1.6133\n",
      "Epoch 20/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3993 - loss: 1.5399 - val_accuracy: 0.3703 - val_loss: 1.6246\n",
      "Epoch 21/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.4029 - loss: 1.5349 - val_accuracy: 0.3832 - val_loss: 1.6004\n",
      "Epoch 22/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4019 - loss: 1.5274 - val_accuracy: 0.3757 - val_loss: 1.6204\n",
      "Epoch 23/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4090 - loss: 1.5212 - val_accuracy: 0.3635 - val_loss: 1.6318\n",
      "Epoch 24/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4060 - loss: 1.5176 - val_accuracy: 0.3837 - val_loss: 1.6162\n",
      "Epoch 25/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4115 - loss: 1.5150 - val_accuracy: 0.3820 - val_loss: 1.6033\n",
      "Epoch 26/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4152 - loss: 1.4997 - val_accuracy: 0.3686 - val_loss: 1.6179\n",
      "Epoch 27/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4163 - loss: 1.4934 - val_accuracy: 0.3715 - val_loss: 1.6120\n",
      "Epoch 28/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.4194 - loss: 1.4891 - val_accuracy: 0.3588 - val_loss: 1.6330\n",
      "Epoch 29/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4181 - loss: 1.4904 - val_accuracy: 0.3738 - val_loss: 1.6236\n",
      "Epoch 30/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4254 - loss: 1.4741 - val_accuracy: 0.3890 - val_loss: 1.6178\n",
      "Epoch 31/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4240 - loss: 1.4819 - val_accuracy: 0.3759 - val_loss: 1.6384\n",
      "Epoch 32/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4225 - loss: 1.4752 - val_accuracy: 0.3790 - val_loss: 1.6275\n",
      "Epoch 33/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4280 - loss: 1.4682 - val_accuracy: 0.3837 - val_loss: 1.6023\n",
      "Epoch 34/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4300 - loss: 1.4622 - val_accuracy: 0.3764 - val_loss: 1.6395\n",
      "Epoch 35/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.4328 - loss: 1.4588 - val_accuracy: 0.3783 - val_loss: 1.6342\n",
      "Epoch 36/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.4364 - loss: 1.4529 - val_accuracy: 0.3762 - val_loss: 1.6304\n",
      "Epoch 37/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4398 - loss: 1.4413 - val_accuracy: 0.3606 - val_loss: 1.6789\n",
      "Epoch 38/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.4366 - loss: 1.4446 - val_accuracy: 0.3778 - val_loss: 1.6579\n",
      "Epoch 39/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4409 - loss: 1.4375 - val_accuracy: 0.3916 - val_loss: 1.6417\n",
      "Epoch 40/40\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4425 - loss: 1.4303 - val_accuracy: 0.3850 - val_loss: 1.6219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26ea2a647f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Rescaling\n",
    "model = Sequential([\n",
    "    Rescaling(1./255,\n",
    "              input_shape=(48,48,1)),  # Tell the model what shape to expect\n",
    "    layers.Flatten(),                 # Convert 48x48x1 to 2304x1 (48*48=2304)\n",
    "    layers.Dense(256,activation=\"relu\"),\n",
    "    layers.Dense(128,activation=\"relu\"),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(32,activation=\"relu\"),\n",
    "    layers.Dense(16,activation=\"relu\"),\n",
    "    layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "model.fit(train_ds,validation_data=val_ds,epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5278d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_training_ds = image_dataset_from_directory(\n",
    "  \"../data/train\",\n",
    "  seed=123,\n",
    "  image_size=(48,48),\n",
    "  batch_size=32,\n",
    "  labels=\"inferred\",\n",
    "  color_mode=\"grayscale\",\n",
    "  label_mode = \"categorical\",\n",
    "\n",
    ")\n",
    "test_training_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0ca4daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4477 - loss: 1.4390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4675579071044922, 0.43724963068962097]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_training_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f5b5450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion_model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model , \"emotion_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe5940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf0857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b78e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
